{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3PhL0c-CMqW"
      },
      "source": [
        "# LIME Explanation for image data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrNIvXZ7CMqc",
        "outputId": "d0fd02fd-22d0-45c9-e637-13b1cec643a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2400 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,DirectoryIterator\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras import backend as K\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import inception_v3 as inc_net\n",
        "# from skimage import io\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "path  =r'./data/images/animals'\n",
        "# Path to train and test directory\n",
        "dir_ = os.path.join(path)\n",
        "\n",
        "\n",
        "# Generate training and test data with Image Generator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255, validation_split = 0.2)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(dir_,target_size=(200, 200),\n",
        "                                                   batch_size= 2400,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=False,\n",
        "                                                   subset = 'training')\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(dir_,target_size = (200,200),\n",
        "                                                  batch_size = 600,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  shuffle=False,\n",
        "                                                  subset = 'validation')\n",
        "\n",
        "\n",
        "# Fetch the data and the labels\n",
        "xtrain, ytrain = next(train_generator)\n",
        "xtest, ytest  = next(test_generator)\n",
        "\n",
        "# Fix the filepath\n",
        "test_filepath = []\n",
        "for filepath in test_generator.filepaths:\n",
        "    filepath = filepath.replace('\\\\', '/')\n",
        "    test_filepath.append(filepath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOYgv644CMqe"
      },
      "source": [
        "## Training the black box model as a CNN network with 3 Conv layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_83vddcXCMqf",
        "outputId": "57c20ec3-9cb0-47e3-fc36-b91382b17a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/160\n",
            "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
            "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
            "Warning! MPI libs are missing, but python applications are still avaiable.\n",
            "[2022-08-10 01:40:33.875 tensorflow-2-6-cpu--ml-r5-24xlarge-d37b532af3012f01b7914fb26ba7:14890 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
            "[2022-08-10 01:40:34.953 tensorflow-2-6-cpu--ml-r5-24xlarge-d37b532af3012f01b7914fb26ba7:14890 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
            "1/1 [==============================] - 31s 31s/step - loss: 1.0999 - precision: 0.0000e+00 - recall: 0.0000e+00 - p-r-c: 0.3431\n",
            "Epoch 2/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 1.5955 - precision: 0.5336 - recall: 0.5192 - p-r-c: 0.4803\n",
            "Epoch 3/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 1.7704 - precision: 0.4536 - recall: 0.4479 - p-r-c: 0.4303\n",
            "Epoch 4/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 1.1995 - precision: 0.5980 - recall: 0.5467 - p-r-c: 0.5981\n",
            "Epoch 5/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.8475 - precision: 0.7922 - recall: 0.2367 - p-r-c: 0.6607\n",
            "Epoch 6/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.8543 - precision: 0.5999 - recall: 0.4517 - p-r-c: 0.6435\n",
            "Epoch 7/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.8701 - precision: 0.6154 - recall: 0.4954 - p-r-c: 0.6607\n",
            "Epoch 8/160\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.8457 - precision: 0.6243 - recall: 0.4875 - p-r-c: 0.6723\n",
            "Epoch 9/160\n"
          ]
        }
      ],
      "source": [
        "cnn_model = Sequential([\n",
        "    # First convolution\n",
        "        Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "    # Second convolution\n",
        "        Conv2D(32, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "    # Third convolution\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Flatten(),\n",
        "    # Dense hidden layer\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "    # Output neuron. \n",
        "        Dense(3, activation='softmax')])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Precision(name=\"precision\"),tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.AUC(name='p-r-c', curve='PR')])\n",
        "history = cnn_model.fit(train_generator, epochs=50, verbose=1)\n",
        "\n",
        "cnn_model.save('./models/image/cnn_model_for_lime.h5')\n",
        "cnn_model = tf.keras.models.load_model('./models/image/cnn_model_for_lime.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8euTNacCMqf"
      },
      "outputs": [],
      "source": [
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage import data, io\n",
        "index_list = np.random.randint(len(xtest), size=9)\n",
        "images= xtest[index_list, :, :, :]\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(10,10))\n",
        "i=0\n",
        "for row in ax:\n",
        "    for col in row:\n",
        "        col.imshow(images[i])\n",
        "        i+=1\n",
        "plt.savefig('./result/dcp_animals.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMxImVahCMqf"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from lime import lime_image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "class_names = {0:'cat', 1:'dog', 2:'panda'}\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "i = np.random.randint(len(xtest))\n",
        "image= xtest[i:i+1, :, :, :]\n",
        "\n",
        "model_output = cnn_model.predict(image)\n",
        "predicted_label = np.argmax(model_output)\n",
        "prob = np.max(model_output)\n",
        "print(f'The CNN model predicted this image as: {class_names[predicted_label]} with probability of {prob:.2f}')\n",
        "\n",
        "explanation = explainer.explain_instance(image[0].astype('double'), cnn_model.predict, top_labels=3, hide_color=0, num_samples=500)\n",
        "\n",
        "# num_features is the number of superpixel (or number of image segmentations)\n",
        "img, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
        "ax1.imshow(image[0])\n",
        "ax2.imshow(mark_boundaries(img, mask))\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "plt.savefig(f'./result/lime_dcp_output{i}.png', dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKb9e-jZCMqg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import json \n",
        "with open('./models/image/imagenet_class_index.json') as f:\n",
        "    labels = json.load(f)\n",
        "\n",
        "inception_model = InceptionV3(weights ='./models/image/inception_v3_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "#transforming the image to the appropriate format\n",
        "def transform_img_to_inception_format(img):    \n",
        "    img = skimage.transform.resize(img, (299,299))\n",
        "    img = (img - 0.5)*2\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    preds = inception_model.predict(img)\n",
        "    top=1\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        result = [tuple(labels[str(i)]) + (pred[i],) for i in top_indices]\n",
        "        result.sort(key=lambda x: x[2], reverse=True)\n",
        "        print(result)\n",
        "    return img, result[0]\n",
        "\n",
        "image_transformed, image_result = transform_img_to_inception_format(image[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Op-UH_MCMqg"
      },
      "source": [
        "## Using the Pre-trained Microsoft ResNet model as a black box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NO_nhhiCMqg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from PIL import Image\n",
        "from transformers import AutoFeatureExtractor, TFResNetForImageClassification\n",
        "\n",
        "print(f'The Inception_V3 model predicted this image as: {image_result[1]} with probability of {image_result[2]:.2f}')\n",
        "\n",
        "explanation = explainer.explain_instance(image_transformed[0], inception_model.predict, top_labels=3, hide_color=0, num_samples=500)\n",
        "\n",
        "# num_features is the number of superpixel (or number of image segmentations)\n",
        "img, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
        "ax1.imshow(image[0])\n",
        "ax2.imshow(mark_boundaries(img, mask))\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "plt.savefig(f'./result/lime_dcp_output{i}.png', dpi=300)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqglrQL9CMqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9KS0sz6CMqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGzVTJnTCMqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PugLJ7wzCMqh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "instance_type": "ml.r5.24xlarge",
    "kernelspec": {
      "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}